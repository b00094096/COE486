{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOplKvSnVr7ks0AhybDHxac",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/b00094096/COE421L10/blob/main/zero_shot_object_detection_with_yolo_world.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ppA0c1DIMiLy"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(HOME)"
      ],
      "metadata": {
        "id": "QxU5IOyKMpnI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q inference-gpu[yolo-world]==0.9.13"
      ],
      "metadata": {
        "id": "92H21wa3Mrbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q supervision==0.19.0rc3"
      ],
      "metadata": {
        "id": "TQO2DBMoMtif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import supervision as sv\n",
        "\n",
        "from tqdm import tqdm\n",
        "from inference.models import YOLOWorld"
      ],
      "metadata": {
        "id": "7a3B3eGCMvNU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Download** **example** **DATA**"
      ],
      "metadata": {
        "id": "lT4kqwKBNij-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i4L_nz63_j56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SOURCE_IMAGE_PATH = f\"{HOME}/dog.jpeg\"\n",
        "SOURCE_VIDEO_PATH = f\"{HOME}/yellow-filling.mp4\""
      ],
      "metadata": {
        "id": "sBkxcz9LNwJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLOWorld(model_id=\"yolo_world/l\")"
      ],
      "metadata": {
        "id": "Pp9GoMMbNyFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = [\"person\", \"backpack\", \"dog\", \"eye\", \"nose\", \"ear\", \"tongue\"]\n",
        "model.set_classes(classes)"
      ],
      "metadata": {
        "id": "6AnShbNyN1cy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = cv2.imread(SOURCE_IMAGE_PATH)\n",
        "results = model.infer(image)\n",
        "detections = sv.Detections.from_inference(results)"
      ],
      "metadata": {
        "id": "gJ__NUJkN2MF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BOUNDING_BOX_ANNOTATOR = sv.BoundingBoxAnnotator(thickness=2)\n",
        "LABEL_ANNOTATOR = sv.LabelAnnotator(text_thickness=2, text_scale=1, text_color=sv.Color.BLACK)"
      ],
      "metadata": {
        "id": "ylngrIyWN40Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "annotated_image = image.copy()\n",
        "annotated_image = BOUNDING_BOX_ANNOTATOR.annotate(annotated_image, detections)\n",
        "annotated_image = LABEL_ANNOTATOR.annotate(annotated_image, detections)\n",
        "sv.plot_image(annotated_image, (10, 10))"
      ],
      "metadata": {
        "id": "ptwTXi8sN6sT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adjusting Confidence Level\n"
      ],
      "metadata": {
        "id": "DpajQ8sSOCRO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that many classes from our prompt were not detected. This is because the default confidence threshold in Inference is set to 0.5. Let's try significantly lowering this value. We've observed that the confidence returned by YOLO-World is significantly lower when querying for classes outside the COCO dataset."
      ],
      "metadata": {
        "id": "SBwkR_8gOHiK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image = cv2.imread(SOURCE_IMAGE_PATH)\n",
        "results = model.infer(image, confidence=0.003)\n",
        "detections = sv.Detections.from_inference(results)"
      ],
      "metadata": {
        "id": "e_cViP4MODsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "By default, `sv.LabelAnnotator` displays only the names of objects. To also view the confidence levels associated with each detection, we must define custom `labels` and pass them to `sv.LabelAnnotator`."
      ],
      "metadata": {
        "id": "LM6qCwPoON86"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = [\n",
        "    f\"{classes[class_id]} {confidence:0.3f}\"\n",
        "    for class_id, confidence\n",
        "    in zip(detections.class_id, detections.confidence)\n",
        "]\n",
        "\n",
        "annotated_image = image.copy()\n",
        "annotated_image = BOUNDING_BOX_ANNOTATOR.annotate(annotated_image, detections)\n",
        "annotated_image = LABEL_ANNOTATOR.annotate(annotated_image, detections, labels=labels)\n",
        "sv.plot_image(annotated_image, (10, 10))"
      ],
      "metadata": {
        "id": "4FlPn0_2OLHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using Non-Max Suppression (NMS) to Eliminate Double Detections\n",
        "\n",
        "To eliminate duplicates, we will use [Non-Max Suppression (NMS)](https://blog.roboflow.com/how-to-code-non-maximum-suppression-nms-in-plain-numpy). NMS evaluates the extent to which detections overlap using the Intersection over Union metric and, upon exceeding a defined threshold, treats them as duplicates. Duplicates are then discarded, starting with those of the lowest confidence. The value should be within the range `[0, 1]`. The smaller the value, the more restrictive the NMS.\n",
        "\n"
      ],
      "metadata": {
        "id": "vd6KW5qSOVE4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5F1dm77LOZ3E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image = cv2.imread(SOURCE_IMAGE_PATH)\n",
        "results = model.infer(image, confidence=0.003)\n",
        "detections = sv.Detections.from_inference(results).with_nms(threshold=0.1)"
      ],
      "metadata": {
        "id": "IUvCyb12OXw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = [\n",
        "    f\"{classes[class_id]} {confidence:0.3f}\"\n",
        "    for class_id, confidence\n",
        "    in zip(detections.class_id, detections.confidence)\n",
        "]\n",
        "\n",
        "annotated_image = image.copy()\n",
        "annotated_image = BOUNDING_BOX_ANNOTATOR.annotate(annotated_image, detections)\n",
        "annotated_image = LABEL_ANNOTATOR.annotate(annotated_image, detections, labels=labels)\n",
        "sv.plot_image(annotated_image, (10, 10))"
      ],
      "metadata": {
        "id": "XXowITYdOcl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Video Processing"
      ],
      "metadata": {
        "id": "ncQg_50sOlaz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The get_video_frames_generator enables us to easily iterate over video frames. Let's create a video generator for our sample input file and display its first frame on the screen."
      ],
      "metadata": {
        "id": "3z9T3qXbOpFK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
        "frame = next(generator)\n",
        "\n",
        "sv.plot_image(frame, (10, 10))"
      ],
      "metadata": {
        "id": "1UIs4awzOmw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = [\"yellow filling\"]\n",
        "model.set_classes(classes)"
      ],
      "metadata": {
        "id": "TWM8KhahOsOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.infer(frame, confidence=0.002)\n",
        "detections = sv.Detections.from_inference(results).with_nms(threshold=0.1)"
      ],
      "metadata": {
        "id": "TcDBJXI6Ouz4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "annotated_image = frame.copy()\n",
        "annotated_image = BOUNDING_BOX_ANNOTATOR.annotate(annotated_image, detections)\n",
        "annotated_image = LABEL_ANNOTATOR.annotate(annotated_image, detections)\n",
        "sv.plot_image(annotated_image, (10, 10))"
      ],
      "metadata": {
        "id": "KuAlklNtOuqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Filtering Detectuions by Area\n"
      ],
      "metadata": {
        "id": "f1iuC_6yO3Eg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "video_info = sv.VideoInfo.from_video_path(SOURCE_VIDEO_PATH)\n",
        "video_info"
      ],
      "metadata": {
        "id": "eUZ-U4qfOyiM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "width, height = video_info.resolution_wh\n",
        "frame_area = width * height\n",
        "frame_area"
      ],
      "metadata": {
        "id": "830ImqJvPQ4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.infer(frame, confidence=0.002)\n",
        "detections = sv.Detections.from_inference(results).with_nms(threshold=0.1)\n",
        "detections.area"
      ],
      "metadata": {
        "id": "jYHL2gykPTka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(detections.area / frame_area) < 0.10"
      ],
      "metadata": {
        "id": "VGf5RKpdPWDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detections = detections[(detections.area / frame_area) < 0.10]\n",
        "\n",
        "annotated_image = frame.copy()\n",
        "annotated_image = BOUNDING_BOX_ANNOTATOR.annotate(annotated_image, detections)\n",
        "annotated_image = LABEL_ANNOTATOR.annotate(annotated_image, detections)\n",
        "sv.plot_image(annotated_image, (10, 10))"
      ],
      "metadata": {
        "id": "sAflzFZePX0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TARGET_VIDEO_PATH = f\"{HOME}/yellow-filling-output.mp4"
      ],
      "metadata": {
        "id": "ub8WZFBGPcDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
        "video_info = sv.VideoInfo.from_video_path(SOURCE_VIDEO_PATH)\n",
        "\n",
        "width, height = video_info.resolution_wh\n",
        "frame_area = width * height\n",
        "frame_area\n",
        "\n",
        "with sv.VideoSink(target_path=TARGET_VIDEO_PATH, video_info=video_info) as sink:\n",
        "    for frame in tqdm(frame_generator, total=video_info.total_frames):\n",
        "        results = model.infer(frame, confidence=0.002)\n",
        "        detections = sv.Detections.from_inference(results).with_nms(threshold=0.1)\n",
        "        detections = detections[(detections.area / frame_area) < 0.10]\n",
        "\n",
        "        annotated_frame = frame.copy()\n",
        "        annotated_frame = BOUNDING_BOX_ANNOTATOR.annotate(annotated_frame, detections)\n",
        "        annotated_frame = LABEL_ANNOTATOR.annotate(annotated_frame, detections)\n",
        "        sink.write_frame(annotated_frame)"
      ],
      "metadata": {
        "id": "KmQcyAb1Pcnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nyutQpiDPfqc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}